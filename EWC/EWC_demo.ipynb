{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python385jvsc74a57bd097ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "C7Ppv-uc9DWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch import autograd\n",
        "# from elastic_weight_consolidation import ElasticWeightConsolidation"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ElasticWeightConsolidation:\n",
        "    def __init__(self, model, crit, device, lr=0.001, weight=1000000):\n",
        "        self.model = model.to(device)\n",
        "        self.weight = weight\n",
        "        self.crit = crit\n",
        "        self.device = device\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr)\n",
        "\n",
        "    def _update_mean_params(self):\n",
        "        for param_name, param in self.model.named_parameters():\n",
        "            _buff_param_name = param_name.replace('.', '__')\n",
        "            self.model.register_buffer(_buff_param_name+'_estimated_mean', param.data.clone())\n",
        "\n",
        "    def _update_fisher_params(self, current_ds, batch_size, num_batch):\n",
        "        dl = DataLoader(current_ds, batch_size, shuffle=True)\n",
        "        log_liklihoods = []\n",
        "        for i, (input, target) in enumerate(dl):\n",
        "            input = input.to(self.device)\n",
        "            target = target.to(self.device)\n",
        "            if i > num_batch:\n",
        "                break\n",
        "            output = F.log_softmax(self.model(input), dim=1)\n",
        "            log_liklihoods.append(output[:, target])\n",
        "        log_likelihood = torch.cat(log_liklihoods).mean()\n",
        "        grad_log_liklihood = autograd.grad(log_likelihood, self.model.parameters())\n",
        "        _buff_param_names = [param[0].replace('.', '__') for param in self.model.named_parameters()]\n",
        "        for _buff_param_name, param in zip(_buff_param_names, grad_log_liklihood):\n",
        "            self.model.register_buffer(_buff_param_name+'_estimated_fisher', param.data.clone() ** 2)\n",
        "\n",
        "    def register_ewc_params(self, dataset, batch_size, num_batches):\n",
        "        self._update_fisher_params(dataset, batch_size, num_batches)\n",
        "        self._update_mean_params()\n",
        "\n",
        "    def _compute_consolidation_loss(self, weight):\n",
        "        try:\n",
        "            losses = []\n",
        "            for param_name, param in self.model.named_parameters():\n",
        "                _buff_param_name = param_name.replace('.', '__')\n",
        "                estimated_mean = getattr(self.model, '{}_estimated_mean'.format(_buff_param_name))\n",
        "                estimated_fisher = getattr(self.model, '{}_estimated_fisher'.format(_buff_param_name))\n",
        "                losses.append((estimated_fisher * (param - estimated_mean) ** 2).sum())\n",
        "            return (weight / 2) * sum(losses)\n",
        "        except AttributeError:\n",
        "            return 0\n",
        "\n",
        "    def forward_backward_update(self, input, target):\n",
        "        input = input.to(self.device)\n",
        "        target = target.to(self.device)\n",
        "        output = self.model(input)\n",
        "        loss = self._compute_consolidation_loss(self.weight) + self.crit(output, target)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def save(self, filename):\n",
        "        torch.save(self.model, filename)\n",
        "\n",
        "    def load(self, filename):\n",
        "        self.model = torch.load(filename)"
      ]
    },
    {
      "metadata": {
        "id": "fUqvbeO79DW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accu(model, dataloader, device):\n",
        "    model = model.eval()    # .to(device)\n",
        "    acc = 0\n",
        "    for input, target in dataloader:\n",
        "        o = model(input.to(device))\n",
        "        acc += (o.argmax(dim=1).long() == target.to(device)).float().mean()\n",
        "    return acc / len(dataloader)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qe22sCzx9DWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_LMkmXG9DWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mnist_train = datasets.MNIST(\"../data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"../data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(mnist_train, batch_size = 100, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size = 100, shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrKlgL6t9zJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LinearLayer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, act='relu', use_bn=False):\n",
        "        super(LinearLayer, self).__init__()\n",
        "        self.use_bn = use_bn\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "        self.act = nn.ReLU() if act == 'relu' else act\n",
        "        if use_bn:\n",
        "            self.bn = nn.BatchNorm1d(output_dim)\n",
        "    def forward(self, x):\n",
        "        if self.use_bn:\n",
        "            return self.bn(self.act(self.lin(x)))\n",
        "        return self.act(self.lin(x))\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44d9meQa9DWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.f1 = Flatten()\n",
        "        self.lin1 = LinearLayer(num_inputs, num_hidden, use_bn=True)\n",
        "        self.lin2 = LinearLayer(num_hidden, num_hidden, use_bn=True)\n",
        "        self.lin3 = nn.Linear(num_hidden, num_outputs)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.lin3(self.lin2(self.lin1(self.f1(x))))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_17XW9359DWf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "crit = nn.CrossEntropyLoss()\n",
        "# ewc = ElasticWeightConsolidation(BaseModel(28 * 28, 100, 10), crit=crit, lr=1e-4)\n",
        "ewc = ElasticWeightConsolidation(BaseModel(28 * 28, 100, 10), crit=crit, lr=1e-4, device=device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gmbrFvJm9DWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "db2ca466-76dc-4d1c-fa32-8dc672a12a8f"
      },
      "cell_type": "code",
      "source": [
        "for _ in range(2):\n",
        "    for input, target in tqdm(train_loader):\n",
        "        ewc.forward_backward_update(input, target)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 600/600 [00:16<00:00, 37.15it/s]\n",
            "100%|██████████| 600/600 [00:14<00:00, 41.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9537, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "accu(ewc.model, test_loader, device)"
      ]
    },
    {
      "metadata": {
        "id": "8HwlRJkI9DWt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ewc.register_ewc_params(mnist_train, 100, 300)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NvJW68IB9DWw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_mnist_train = datasets.FashionMNIST(\"../data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "f_mnist_test = datasets.FashionMNIST(\"../data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "f_train_loader = DataLoader(f_mnist_train, batch_size = 100, shuffle=True)\n",
        "f_test_loader = DataLoader(f_mnist_test, batch_size = 100, shuffle=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzQbVudz9DWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "bdcb55c5-d40a-4a7a-dca5-4652076e8033"
      },
      "cell_type": "code",
      "source": [
        "for _ in range(2):\n",
        "    for input, target in tqdm(f_train_loader):\n",
        "        ewc.forward_backward_update(input, target)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 600/600 [00:18<00:00, 32.92it/s]\n",
            "100%|██████████| 600/600 [00:20<00:00, 28.69it/s]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "L8n6PX5w9DW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ewc.register_ewc_params(f_mnist_train, 100, 300)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aOIOBZhp9DW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b260dee2-3c7d-4a9f-be83-8ac412a32f5c"
      },
      "cell_type": "code",
      "source": [
        "accu(ewc.model, f_test_loader, device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7977, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "hFdW_33Y9DW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38b2dad0-bfb4-48e5-ec01-d848cc8c1593"
      },
      "cell_type": "code",
      "source": [
        "accu(ewc.model, test_loader, device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9497, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "Fkni7xkY-tRI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for _ in range(1):\n",
        "    for index, (input, target) in enumerate(f_test_loader):\n",
        "        if index<1:\n",
        "            print(ewc.model(input[0:4].to(device)))\n",
        "            print(target[0:4])\n",
        "\n",
        "for _ in range(1):\n",
        "    for index, (input, target) in enumerate(test_loader):\n",
        "        if index<1:\n",
        "            print(ewc.model(input[0:4].to(device)))\n",
        "            print(target[0:4])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.2218, -0.7605, -0.7667, -1.1336, -0.4702,  1.9325, -2.6517,  2.0251,\n",
            "         -0.3380,  2.3826],\n",
            "        [-1.0768, -1.5262,  6.0297, -0.4847,  3.0193, -4.1753,  3.5122, -3.2434,\n",
            "         -0.8368, -3.8094],\n",
            "        [ 1.1982,  5.9452, -0.1854,  0.8599, -1.3951, -3.2498, -0.3939,  0.7331,\n",
            "         -4.5451, -0.3555],\n",
            "        [-0.7796,  6.7479, -0.5740,  2.0298, -2.2204, -2.9785,  0.7256, -0.5305,\n",
            "         -4.2782, -0.1345]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([9, 2, 1, 1])\n",
            "tensor([[ 0.9272, -0.7868,  1.1933,  0.5485, -0.9731, -1.1345, -1.2602,  6.5175,\n",
            "         -2.0585,  0.1798],\n",
            "        [-0.5558,  0.2415,  5.0362,  1.8427, -1.4949, -0.0082,  0.3034, -1.7884,\n",
            "         -1.2401, -2.6832],\n",
            "        [-0.7213,  5.8563, -0.1411, -1.2685, -1.0508,  0.3604,  0.2270, -0.6103,\n",
            "         -1.7471, -0.3579],\n",
            "        [ 5.9507, -0.6688, -0.8824, -0.9312, -0.1650, -0.1033,  1.3465, -0.2621,\n",
            "         -1.3169, -0.2685]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([7, 2, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}