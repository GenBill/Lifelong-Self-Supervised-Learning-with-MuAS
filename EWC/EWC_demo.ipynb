{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "C7Ppv-uc9DWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch import autograd\n",
        "# from elastic_weight_consolidation import ElasticWeightConsolidation"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ElasticWeightConsolidation:\n",
        "    def __init__(self, model, crit, device, lr=0.001, weight=1000000):\n",
        "        self.model = model.to(device)\n",
        "        self.weight = weight\n",
        "        self.crit = crit\n",
        "        self.device = device\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr)\n",
        "\n",
        "    def _update_mean_params(self):\n",
        "        for param_name, param in self.model.named_parameters():\n",
        "            _buff_param_name = param_name.replace('.', '__')\n",
        "            self.model.register_buffer(_buff_param_name+'_estimated_mean', param.data.clone())\n",
        "\n",
        "    def _update_fisher_params(self, current_ds, batch_size, num_batch):\n",
        "        dl = DataLoader(current_ds, batch_size, shuffle=True)\n",
        "        log_liklihoods = []\n",
        "        for i, (input, target) in enumerate(dl):\n",
        "            input = input.to(self.device)\n",
        "            target = target.to(self.device)\n",
        "            if i > num_batch:\n",
        "                break\n",
        "            output = F.log_softmax(self.model(input), dim=1)\n",
        "            log_liklihoods.append(output[:, target])\n",
        "        log_likelihood = torch.cat(log_liklihoods).mean()\n",
        "        grad_log_liklihood = autograd.grad(log_likelihood, self.model.parameters())\n",
        "        _buff_param_names = [param[0].replace('.', '__') for param in self.model.named_parameters()]\n",
        "        for _buff_param_name, param in zip(_buff_param_names, grad_log_liklihood):\n",
        "            self.model.register_buffer(_buff_param_name+'_estimated_fisher', param.data.clone() ** 2)\n",
        "\n",
        "    def register_ewc_params(self, dataset, batch_size, num_batches):\n",
        "        self._update_fisher_params(dataset, batch_size, num_batches)\n",
        "        self._update_mean_params()\n",
        "\n",
        "    def _compute_consolidation_loss(self, weight):\n",
        "        try:\n",
        "            losses = []\n",
        "            for param_name, param in self.model.named_parameters():\n",
        "                _buff_param_name = param_name.replace('.', '__')\n",
        "                estimated_mean = getattr(self.model, '{}_estimated_mean'.format(_buff_param_name))\n",
        "                estimated_fisher = getattr(self.model, '{}_estimated_fisher'.format(_buff_param_name))\n",
        "                losses.append((estimated_fisher * (param - estimated_mean) ** 2).sum())\n",
        "            return (weight / 2) * sum(losses)\n",
        "        except AttributeError:\n",
        "            return 0\n",
        "\n",
        "    def forward_backward_update(self, input, target):\n",
        "        input = input.to(self.device)\n",
        "        target = target.to(self.device)\n",
        "        output = self.model(input)\n",
        "        loss = self._compute_consolidation_loss(self.weight) + self.crit(output, target)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def save(self, filename):\n",
        "        torch.save(self.model, filename)\n",
        "\n",
        "    def load(self, filename):\n",
        "        self.model = torch.load(filename)"
      ]
    },
    {
      "metadata": {
        "id": "fUqvbeO79DW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accu(model, dataloader, device):\n",
        "    model = model.eval()    # .to(device)\n",
        "    acc = 0\n",
        "    for input, target in dataloader:\n",
        "        o = model(input.to(device))\n",
        "        acc += (o.argmax(dim=1).long() == target.to(device)).float().mean()\n",
        "    return acc / len(dataloader)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qe22sCzx9DWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_LMkmXG9DWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mnist_train = datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(mnist_train, batch_size = 100, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size = 100, shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrKlgL6t9zJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LinearLayer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, act='relu', use_bn=False):\n",
        "        super(LinearLayer, self).__init__()\n",
        "        self.use_bn = use_bn\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "        self.act = nn.ReLU() if act == 'relu' else act\n",
        "        if use_bn:\n",
        "            self.bn = nn.BatchNorm1d(output_dim)\n",
        "    def forward(self, x):\n",
        "        if self.use_bn:\n",
        "            return self.bn(self.act(self.lin(x)))\n",
        "        return self.act(self.lin(x))\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44d9meQa9DWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.f1 = Flatten()\n",
        "        self.lin1 = LinearLayer(num_inputs, num_hidden, use_bn=True)\n",
        "        self.lin2 = LinearLayer(num_hidden, num_hidden, use_bn=True)\n",
        "        self.lin3 = nn.Linear(num_hidden, num_outputs)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.lin3(self.lin2(self.lin1(self.f1(x))))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_17XW9359DWf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "crit = nn.CrossEntropyLoss()\n",
        "# ewc = ElasticWeightConsolidation(BaseModel(28 * 28, 100, 10), crit=crit, lr=1e-4)\n",
        "ewc = ElasticWeightConsolidation(BaseModel(28 * 28, 100, 10), crit=crit, lr=1e-4, device=device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gmbrFvJm9DWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "db2ca466-76dc-4d1c-fa32-8dc672a12a8f"
      },
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    for input, target in tqdm(train_loader):\n",
        "        ewc.forward_backward_update(input, target)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 600/600 [00:08<00:00, 69.72it/s]\n",
            "100%|██████████| 600/600 [00:08<00:00, 72.76it/s]\n",
            "100%|██████████| 600/600 [00:08<00:00, 68.84it/s]\n",
            "100%|██████████| 600/600 [00:08<00:00, 71.50it/s]\n",
            "100%|██████████| 600/600 [00:08<00:00, 73.53it/s]\n",
            "100%|██████████| 600/600 [00:08<00:00, 72.68it/s]\n",
            "100%|██████████| 600/600 [00:08<00:00, 73.32it/s]\n",
            "100%|██████████| 600/600 [00:08<00:00, 72.73it/s]\n",
            "100%|██████████| 600/600 [00:08<00:00, 71.80it/s]\n",
            "100%|██████████| 600/600 [00:07<00:00, 75.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9769, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "accu(ewc.model, test_loader, device)"
      ]
    },
    {
      "metadata": {
        "id": "8HwlRJkI9DWt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ewc.register_ewc_params(mnist_train, 100, 300)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NvJW68IB9DWw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_mnist_train = datasets.FashionMNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "f_mnist_test = datasets.FashionMNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "f_train_loader = DataLoader(f_mnist_train, batch_size = 100, shuffle=True)\n",
        "f_test_loader = DataLoader(f_mnist_test, batch_size = 100, shuffle=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzQbVudz9DWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "bdcb55c5-d40a-4a7a-dca5-4652076e8033"
      },
      "cell_type": "code",
      "source": [
        "for _ in range(20):\n",
        "    for input, target in tqdm(f_train_loader):\n",
        "        ewc.forward_backward_update(input, target)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 600/600 [00:10<00:00, 55.84it/s]\n",
            "100%|██████████| 600/600 [00:10<00:00, 57.26it/s]\n",
            "100%|██████████| 600/600 [00:10<00:00, 59.30it/s]\n",
            "100%|██████████| 600/600 [00:10<00:00, 58.66it/s]\n",
            "100%|██████████| 600/600 [00:10<00:00, 58.84it/s]\n",
            "100%|██████████| 600/600 [00:10<00:00, 58.59it/s]\n",
            "100%|██████████| 600/600 [00:10<00:00, 58.60it/s]\n",
            "100%|██████████| 600/600 [00:09<00:00, 60.18it/s]\n",
            "100%|██████████| 600/600 [00:10<00:00, 59.57it/s]\n",
            "100%|██████████| 600/600 [00:10<00:00, 58.39it/s]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "L8n6PX5w9DW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ewc.register_ewc_params(f_mnist_train, 100, 300)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aOIOBZhp9DW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b260dee2-3c7d-4a9f-be83-8ac412a32f5c"
      },
      "cell_type": "code",
      "source": [
        "accu(ewc.model, f_test_loader, device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7999, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "hFdW_33Y9DW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38b2dad0-bfb4-48e5-ec01-d848cc8c1593"
      },
      "cell_type": "code",
      "source": [
        "accu(ewc.model, test_loader, device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9736, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "Fkni7xkY-tRI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [],
      "execution_count": 0,
      "outputs": []
    }
  ]
}